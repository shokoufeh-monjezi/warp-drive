{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34e0d19",
   "metadata": {},
   "source": [
    "# Fast Multi-agent Reinforcement Learning on a GPU using WarpDrive and Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de08d1",
   "metadata": {},
   "source": [
    "Try this notebook on [Colab](http://colab.research.google.com/github/salesforce/warp-drive/blob/master/tutorials/tutorial-7-training_with_warp_drive_and_pytorch_lightning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419e3d3",
   "metadata": {},
   "source": [
    "# ⚠️ PLEASE NOTE:\n",
    "This notebook runs on a GPU runtime.\\\n",
    "If running on Colab, choose Runtime > Change runtime type from the menu, then select `GPU` in the 'Hardware accelerator' dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aec80f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert torch.cuda.device_count() > 0, \"This notebook needs a GPU to run!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015777a",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed3b83",
   "metadata": {},
   "source": [
    "This tutorial shows how [WarpDrive](https://github.com/salesforce/warp-drive) can be used together with [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning).\n",
    "\n",
    "WarpDrive is a flexible, lightweight, and easy-to-use RL framework that implements end-to-end deep multi-agent RL on a single GPU (Graphics Processing Unit). Using the extreme parallelization capability of GPUs, it enables [orders-of-magnitude faster RL](https://arxiv.org/abs/2108.13976) compared to common implementations that blend CPU simulations and GPU models. WarpDrive is extremely efficient as it runs simulations across multiple agents and multiple environment replicas in parallel and completely eliminates the back-and-forth data copying between the CPU and the GPU.\n",
    "\n",
    "Pytorch Lightning is a machine learning framework which [greatly reduces trainer boilerplate code](https://www.pytorchlightning.ai/), and improves training modularity and flexibility. It abstracts away most of the engineering pieces of code, so users can focus on research and building models, and iterate on experiments really fast. Pytorch Lightning also provides support for easily running the model on any hardware, performing distributed training, model checkpointing, performance profiling, logging and visualization.\n",
    "\n",
    "Below, we demonstrate how to use WarpDrive and PytorchLightning together to train a game of [Tag](https://github.com/salesforce/warp-drive/blob/master/example_envs/tag_continuous/tag_continuous.py) where multiple *tagger* agents are trying to run after and tag multiple other *runner* agents. As such, the Warpdrive framework comprises several utility functions that help easily implement any (OpenAI-)*gym-style* RL environment, and furthermore, provides quality-of-life tools to train it end-to-end using just a few lines of code. You may familiarize yourself with WarpDrive with the help of these [tutorials](https://github.com/salesforce/warp-drive/tree/master/tutorials).\n",
    "\n",
    "We invite everyone to **contribute to WarpDrive**, including adding new multi-agent environments, proposing new features and reporting issues on our open source [repository](https://github.com/salesforce/warp-drive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56400116",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1902916",
   "metadata": {},
   "source": [
    "This notebook requires the `rl-warp-drive` as well as the `pytorch-lightning` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4b0e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rl_warp_drive in /home/jupyter/.local/lib/python3.8/site-packages (1.6.7)\n",
      "Requirement already satisfied: gym>=0.18 in /home/jupyter/.local/lib/python3.8/site-packages (from rl_warp_drive) (0.25.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /opt/conda/lib/python3.8/site-packages (from rl_warp_drive) (5.4.1)\n",
      "Requirement already satisfied: pycuda==2021.1 in /opt/conda/lib/python3.8/site-packages (from rl_warp_drive) (2021.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.1 in /opt/conda/lib/python3.8/site-packages (from rl_warp_drive) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.8/site-packages (from rl_warp_drive) (1.21.2)\n",
      "Requirement already satisfied: torch<1.11,>=1.9 in /opt/conda/lib/python3.8/site-packages (from rl_warp_drive) (1.10.0a0+3fd9dcf)\n",
      "Requirement already satisfied: pytest>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from rl_warp_drive) (6.2.4)\n",
      "Requirement already satisfied: pytools>=2011.2 in /opt/conda/lib/python3.8/site-packages (from pycuda==2021.1->rl_warp_drive) (2022.1.7)\n",
      "Requirement already satisfied: mako in /opt/conda/lib/python3.8/site-packages (from pycuda==2021.1->rl_warp_drive) (1.2.0)\n",
      "Requirement already satisfied: appdirs>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from pycuda==2021.1->rl_warp_drive) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/jupyter/.local/lib/python3.8/site-packages (from gym>=0.18->rl_warp_drive) (4.12.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/jupyter/.local/lib/python3.8/site-packages (from gym>=0.18->rl_warp_drive) (0.0.7)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/jupyter/.local/lib/python3.8/site-packages (from gym>=0.18->rl_warp_drive) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jupyter/.local/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym>=0.18->rl_warp_drive) (3.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.1->rl_warp_drive) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.1->rl_warp_drive) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.1->rl_warp_drive) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.1->rl_warp_drive) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.1->rl_warp_drive) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=3.2.1->rl_warp_drive) (1.16.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.8/site-packages (from pytest>=6.1.0->rl_warp_drive) (0.10.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.8/site-packages (from pytest>=6.1.0->rl_warp_drive) (21.2.0)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/conda/lib/python3.8/site-packages (from pytest>=6.1.0->rl_warp_drive) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.8/site-packages (from pytest>=6.1.0->rl_warp_drive) (1.10.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from pytest>=6.1.0->rl_warp_drive) (21.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.8/site-packages (from pytest>=6.1.0->rl_warp_drive) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /opt/conda/lib/python3.8/site-packages (from pytools>=2011.2->pycuda==2021.1->rl_warp_drive) (4.2.0)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from pytools>=2011.2->pycuda==2021.1->rl_warp_drive) (2.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.8/site-packages (from mako->pycuda==2021.1->rl_warp_drive) (2.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch_lightning>=1.4 in /home/jupyter/.local/lib/python3.8/site-packages (1.6.5)\n",
      "Requirement already satisfied: torch>=1.8.* in /opt/conda/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (1.10.0a0+3fd9dcf)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (1.21.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (2.6.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (21.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (3.17.3)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /home/jupyter/.local/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (0.3.2)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/jupyter/.local/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (2022.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (5.4.1)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /home/jupyter/.local/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (0.9.3)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (4.62.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch_lightning>=1.4) (4.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/jupyter/.local/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (3.8.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (2.26.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->pytorch_lightning>=1.4) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.8/site-packages (from protobuf<=3.20.1->pytorch_lightning>=1.4) (1.16.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (0.4.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (1.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (0.13.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (2.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (1.39.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (1.34.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.4) (57.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning>=1.4) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning>=1.4) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning>=1.4) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning>=1.4) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning>=1.4) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning>=1.4) (3.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/jupyter/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jupyter/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jupyter/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jupyter/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jupyter/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning>=1.4) (21.2.0)\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -U rl_warp_drive\n",
    "\n",
    "! pip install 'pytorch_lightning>=1.4'\n",
    "\n",
    "# Also ,install ffmpeg for visualizing animations\n",
    "! apt install ffmpeg --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20cf7888-c0d5-4d95-a81c-a10db14596e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new\n",
    "import logging\n",
    "\n",
    "from example_envs.tag_continuous.tag_continuous import TagContinuous\n",
    "from example_envs.tag_continuous.generate_rollout_animation import (\n",
    "    generate_tag_env_rollout_animation,\n",
    ")\n",
    "from IPython.display import HTML\n",
    "from pytorch_lightning import Trainer\n",
    "from warp_drive.env_wrapper import EnvWrapper\n",
    "from warp_drive.training.pytorch_lightning import (\n",
    "    CUDACallback,\n",
    "    PerfStatsCallback,\n",
    "    WarpDriveModule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75a8f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from example_envs.tag_continuous.tag_continuous import TagContinuous\n",
    "from example_envs.tag_continuous.generate_rollout_animation import (\n",
    "    generate_tag_env_rollout_animation,\n",
    ")\n",
    "from IPython.display import HTML\n",
    "from pytorch_lightning import Trainer\n",
    "from warp_drive.env_wrapper import EnvWrapper\n",
    "from warp_drive.training.pytorch_lightning import (\n",
    "    CUDACallback,\n",
    "    PerfStatsCallback,\n",
    "    WarpDriveModule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cc6c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logger level e.g., DEBUG, INFO, WARNING, ERROR.\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a345ef",
   "metadata": {},
   "source": [
    "# Specify a set of run configurations for your experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28ee03",
   "metadata": {},
   "source": [
    "The run configuration is a dictionary comprising the environment parameters, the trainer and the policy network settings, as well as configurations for saving.\n",
    "\n",
    "For our experiment, we consider an environment wherein $5$ taggers and $100$ runners play the game of [Tag](https://github.com/salesforce/warp-drive/blob/master/example_envs/tag_continuous/tag_continuous.py) on a $20 \\times 20$ plane. The game lasts $200$ timesteps. Each agent chooses it's own acceleration and turn actions at every timestep, and we use mechanics to determine how the agents move over the grid. When a tagger gets close to a runner, the runner is tagged, and is eliminated from the game. For the configuration below, the runners and taggers have the same unit skill levels, or top speeds.\n",
    "\n",
    "We train the agents using $50$ environments or simulations running in parallel. With WarpDrive, each simulation runs on sepate GPU blocks.\n",
    "\n",
    "There are two separate policy networks used for the tagger and runner agents. Each network is a fully-connected model with two layers each of $256$ dimensions. We use the Advantage Actor Critic (A2C) algorithm for training. WarpDrive also currently provides the option to use the Proximal Policy Optimization (PPO) algorithm instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0136641",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = dict(\n",
    "    name=\"tag_continuous\",\n",
    "    # Environment settings.\n",
    "    env=dict(\n",
    "        num_taggers=5,  # number of taggers in the environment\n",
    "        num_runners=100,  # number of runners in the environment\n",
    "        grid_length=20.0,  # length of the (square) grid on which the game is played\n",
    "        episode_length=200,  # episode length in timesteps\n",
    "        max_acceleration=0.1,  # maximum acceleration\n",
    "        min_acceleration=-0.1,  # minimum acceleration\n",
    "        max_turn=2.35,  # 3*pi/4 radians\n",
    "        min_turn=-2.35,  # -3*pi/4 radians\n",
    "        num_acceleration_levels=10,  # number of discretized accelerate actions\n",
    "        num_turn_levels=10,  # number of discretized turn actions\n",
    "        skill_level_tagger=1.0,  # skill level for the tagger\n",
    "        skill_level_runner=1.0,  # skill level for the runner\n",
    "        use_full_observation=False,  # each agent only sees full or partial information\n",
    "        runner_exits_game_after_tagged=True,  # flag to indicate if a runner stays in the game after getting tagged\n",
    "        num_other_agents_observed=10,  # number of other agents each agent can see\n",
    "        tag_reward_for_tagger=10.0,  # positive reward for the tagger upon tagging a runner\n",
    "        tag_penalty_for_runner=-10.0,  # negative reward for the runner upon getting tagged\n",
    "        end_of_game_reward_for_runner=1.0,  # reward at the end of the game for a runner that isn't tagged\n",
    "        tagging_distance=0.02,  # margin between a tagger and runner to consider the runner as 'tagged'.\n",
    "    ),\n",
    "    # Trainer settings.\n",
    "    trainer=dict(\n",
    "        num_envs=50,  # number of environment replicas (number of GPU blocks used)\n",
    "        train_batch_size=10000,  # total batch size used for training per iteration (across all the environments)\n",
    "        num_episodes=500,  # total number of episodes to run the training for (can be arbitrarily high!)\n",
    "    ),\n",
    "    # Policy network settings.\n",
    "    policy=dict(\n",
    "        runner=dict(\n",
    "            to_train=True,  # flag indicating whether the model needs to be trained\n",
    "            algorithm=\"A2C\",  # algorithm used to train the policy\n",
    "            gamma=0.98,  # discount rate\n",
    "            lr=0.005,  # learning rate\n",
    "            model=dict(\n",
    "                type=\"fully_connected\", fc_dims=[256, 256], model_ckpt_filepath=\"\"\n",
    "            ),  # policy model settings\n",
    "        ),\n",
    "        tagger=dict(\n",
    "            to_train=True,\n",
    "            algorithm=\"A2C\",\n",
    "            gamma=0.98,\n",
    "            lr=0.002,\n",
    "            model=dict(\n",
    "                type=\"fully_connected\", fc_dims=[256, 256], model_ckpt_filepath=\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    # Checkpoint saving setting.\n",
    "    saving=dict(\n",
    "        metrics_log_freq=10,  # how often (in iterations) to print the metrics\n",
    "        model_params_save_freq=5000,  # how often (in iterations) to save the model parameters\n",
    "        basedir=\"/tmp\",  # base folder used for saving\n",
    "        name=\"continuous_tag\",  # experiment name\n",
    "        tag=\"example\",  # experiment tag\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bee726",
   "metadata": {},
   "source": [
    "# Instantiate the WarpDrive Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e9a6c",
   "metadata": {},
   "source": [
    "In order to instantiate the WarpDrive module, we first use an environment wrapper to specify that the environment needs to be run on the GPU (via the `use_cuda` flag). Also, agents in the environment can share policy models; so we specify a dictionary to map each policy network model to the list of agent ids using that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d274738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1659047787\n"
     ]
    }
   ],
   "source": [
    "# Create a wrapped environment object via the EnvWrapper.\n",
    "# Ensure that use_cuda is set to True (in order to run on the GPU).\n",
    "env_wrapper = EnvWrapper(\n",
    "    TagContinuous(**run_config[\"env\"]),\n",
    "    num_envs=run_config[\"trainer\"][\"num_envs\"],\n",
    "    use_cuda=True,\n",
    ")\n",
    "\n",
    "# Agents can share policy models: this dictionary maps policy model names to agent ids.\n",
    "policy_tag_to_agent_id_map = {\n",
    "    \"tagger\": list(env_wrapper.env.taggers),\n",
    "    \"runner\": list(env_wrapper.env.runners),\n",
    "}\n",
    "\n",
    "wd_module = WarpDriveModule(\n",
    "    env_wrapper=env_wrapper,\n",
    "    config=run_config,\n",
    "    policy_tag_to_agent_id_map=policy_tag_to_agent_id_map,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77375890",
   "metadata": {},
   "source": [
    "# Visualizing an episode roll-out before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424276e",
   "metadata": {},
   "source": [
    "We will use the `generate_tag_env_rollout_animation()` helper function in order to visualize an episode rollout. Internally, this function uses the WarpDrive module's `fetch_episode_states` to fetch the data arrays on the GPU for the duration of an entire episode. Specifically, we fetch the state arrays pertaining to agents' x and y locations on the plane and indicators on which agents are still active in the game, and will use these to visualize an episode roll-out. Note that this function may be invoked at any time during training, and it will use the state of the policy models at that time to sample actions and generate the visualization.\n",
    "\n",
    "The animation below shows a sample realization of the game episode before training, i.e., with randomly chosen agent actions. The $5$ taggers are marked in pink, while the $100$ blue agents are the runners. Both the taggers and runners move around randomly and about half the runners remain at the end of the episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5721b2b3-2547-45e2-8e35-f87019e3ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell doesn't work on quick deploy since we don't have sudo access. Uncomment the next cell if you run without quick deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8654a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anim = generate_tag_env_rollout_animation(wd_module, fps=25)\n",
    "#HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeaafc9",
   "metadata": {},
   "source": [
    "# Create the Lightning Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dbc5ff",
   "metadata": {},
   "source": [
    "Next, we create the trainer for training the WarpDrive model. We add the `performance stats` callbacks to the trainer to view the throughput performance of WarpDrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29547bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.distributed' has no attribute 'is_torchelastic_launched'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/1033584561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Set reload_dataloaders_every_n_epochs=1 to invoke\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# train_dataloader() each epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0maccelerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_connector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiple_trainloader_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         self._accelerator_connector = AcceleratorConnector(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_parallel_devices_and_init_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# 3. Instantiate ClusterEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m_set_parallel_devices_and_init_accelerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_devices_flag_if_auto_select_gpus_passed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_devices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parallel_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu.py\u001b[0m in \u001b[0;36mparse_devices\u001b[0;34m(devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;34m\"\"\"Accelerator device parsing logic.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdevice_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\u001b[0m in \u001b[0;36mparse_gpu_ids\u001b[0;34m(gpus)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPUs requested but none are available.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mTorchElasticEnvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_all_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;31m# omit sanity check on torchelastic as by default shows one visible GPU per process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/environments/torchelastic_environment.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_TORCH_GREATER_EQUAL_1_9_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# if not available (for example on MacOS), `is_torchelastic_launched` is not defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_torchelastic_launched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mrequired_env_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"RANK\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GROUP_RANK\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LOCAL_RANK\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LOCAL_WORLD_SIZE\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrequired_env_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.distributed' has no attribute 'is_torchelastic_launched'"
     ]
    }
   ],
   "source": [
    "log_freq = run_config[\"saving\"][\"metrics_log_freq\"]\n",
    "\n",
    "# Define callbacks.\n",
    "cuda_callback = CUDACallback(module=wd_module)\n",
    "perf_stats_callback = PerfStatsCallback(\n",
    "    batch_size=wd_module.training_batch_size,\n",
    "    num_iters=wd_module.num_iters,\n",
    "    log_freq=log_freq,\n",
    ")\n",
    "\n",
    "# Instantiate the PytorchLightning trainer with the callbacks.\n",
    "# # Also, set the number of gpus to 1, since this notebook uses just a single GPU.\n",
    "num_gpus = 1\n",
    "num_episodes = run_config[\"trainer\"][\"num_episodes\"]\n",
    "episode_length = run_config[\"env\"][\"episode_length\"]\n",
    "training_batch_size = run_config[\"trainer\"][\"train_batch_size\"]\n",
    "num_epochs = num_episodes * episode_length / training_batch_size\n",
    "\n",
    "# Set reload_dataloaders_every_n_epochs=1 to invoke\n",
    "# train_dataloader() each epoch.\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=num_gpus,\n",
    "    callbacks=[cuda_callback, perf_stats_callback],\n",
    "    max_epochs=num_epochs,\n",
    "    reload_dataloaders_every_n_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef70e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cbf5d2596f0a274e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cbf5d2596f0a274e\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88638f2f",
   "metadata": {},
   "source": [
    "# Train the WarpDrive Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa521de5",
   "metadata": {},
   "source": [
    "Finally, we invoke training.\n",
    "\n",
    "Note: please scroll up to the tensorboard cell to visualize the curves during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85a43fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/4041223140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwd_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(wd_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc0211",
   "metadata": {},
   "source": [
    "## Visualize an episode-rollout after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = generate_tag_env_rollout_animation(wd_module, fps=25)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79665ae",
   "metadata": {},
   "source": [
    "Note: In the configuration above, we have set the trainer to only train on $50000$ rollout episodes, but you can increase the `num_episodes` configuration parameter to train further. As more training happens, the runners learn to escape the taggers, and the taggers learn to chase after the runner. Sometimes, the taggers also collaborate to team-tag runners. A good number of episodes to train on (for the configuration we have used) is $2$M or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, close the WarpDrive module to clear up the CUDA memory heap\n",
    "wd_module.graceful_close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca3b74",
   "metadata": {},
   "source": [
    "# Learn More about WarpDrive and explore our tutorials!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489647a7",
   "metadata": {},
   "source": [
    "1. [WarpDrive basics](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-1-warp_drive_basics.ipynb)\n",
    "2. [WarpDrive sampler](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-2-warp_drive_sampler.ipynb)\n",
    "3. [WarpDrive reset and log](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-3-warp_drive_reset_and_log.ipynb)\n",
    "4. [Creating custom environments](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-4-create_custom_environments.md)\n",
    "5. [Training with WarpDrive](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-5-training_with_warp_drive.ipynb)\n",
    "6. [Scaling Up training with WarpDrive](https://www.github.com/salesforce/warp-drive/blob/master/tutorials/tutorial-6-scaling_up_training_with_warp_drive.md)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Custom [warpdrive] (Local)",
   "language": "python",
   "name": "local-nvcr.io_partners_salesforce_warpdrive_v1.0__python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
